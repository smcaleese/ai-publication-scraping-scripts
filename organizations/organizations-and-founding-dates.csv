name,researchers,year
Center for AI Safety (CAIS),10,2022
Fund for Alignment Research (FAR),10,2022
Conjecture,10,2022
Aligned AI,4,2022
Apart Research,4,2022
Encultured AI,2,2022
Algorithmic Alignment Group (MIT),5,2021
Anthropic,15,2021
Sam Bowman,8,2020
Jacob Steinhardt,8,2016
David Krueger,7,2016
Redwood Research,12,2021
Alignment Research Center (ARC),2,2021
Other,50,2018
Center for Human-Compatible AI,30,2016
OpenAI,20,2016
GoodAI,10,2014
DeepMind,20,2012
Future of Humanity Institute (FHI),10,2005
Machine Intelligence Research Institute (MIRI),15,2000